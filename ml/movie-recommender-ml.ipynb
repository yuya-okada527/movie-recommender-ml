{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 17.2MB/s ta 0:00:01\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-20.1.1\n",
      "\u001b[33mYou are using pip version 20.1.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-2.10.0-py3-none-any.whl (660 kB)\n",
      "\u001b[K     |████████████████████████████████| 660 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 48.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.6)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 67.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 69.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.5.14-cp36-cp36m-manylinux2010_x86_64.whl (675 kB)\n",
      "\u001b[K     |████████████████████████████████| 675 kB 66.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (3.0.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2.20.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.15.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.11.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (6.7)\n",
      "Collecting joblib\n",
      "  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 63.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (1.23)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2019.11.28)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893264 sha256=150e8f234583c2f1a726a22e2ec271b8a85af12d2c5577aa46c77683cea4025b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, joblib, sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed joblib-0.15.1 regex-2020.5.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "granola_ids [101, 12604, 6030, 6963, 102]\n",
      "type of granola_ids <class 'list'>\n",
      "granola_tokens ['[CLS]', 'gran', '##ola', 'bars', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "granola_ids = tokenizer.encode(\"granola bars\")\n",
    "print(\"granola_ids\", granola_ids)\n",
    "print(\"type of granola_ids\", type(granola_ids))\n",
    "print(\"granola_tokens\", tokenizer.convert_ids_to_tokens(granola_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "granola_ids tensor([  101, 12604,  6030,  6963,   102])\n",
      "type of granola_ids <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "granola_ids = torch.LongTensor(granola_ids)\n",
    "print(\"granola_ids\", granola_ids)\n",
    "print(\"type of granola_ids\", type(granola_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "device = \"cude\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "granola_ids = granola_ids.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'tuple'>\n",
      "3\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(granola_ids.size())\n",
    "granola_ids = granola_ids.unsqueeze(0)\n",
    "print(granola_ids.size())\n",
    "\n",
    "print(type(granola_ids))\n",
    "with torch.no_grad():\n",
    "    out = model(input_ids=granola_ids)\n",
    "\n",
    "    \n",
    "print(type(out))\n",
    "print(len(out))\n",
    "hidden_states = out[2]\n",
    "print(len(hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.7497e-01,  1.8313e-01, -8.8652e-02,  2.1698e-01,  3.1942e-01,\n",
      "        -1.1412e-01,  7.4039e-02,  3.7655e-01, -4.1821e-01,  9.9971e-02,\n",
      "        -9.0241e-02, -2.4298e-01,  1.5542e-01,  4.2042e-01, -2.5547e-01,\n",
      "         2.9753e-01, -2.9643e-01, -2.5810e-02,  8.5306e-02,  1.0182e-01,\n",
      "         3.0401e-01, -4.4263e-01,  3.1249e-02,  1.4435e-01,  3.0189e-01,\n",
      "         7.3914e-02, -2.5580e-01,  3.1383e-01, -1.4688e-01, -1.5202e-01,\n",
      "         7.0786e-02,  4.0447e-01, -1.1769e-01,  3.1848e-01,  2.8021e-02,\n",
      "        -1.6934e-01,  3.5639e-01, -2.2931e-01, -1.1899e-01, -1.1182e-01,\n",
      "        -1.6003e-01,  7.9355e-02,  5.1107e-01,  5.2224e-02, -1.5481e-01,\n",
      "         2.8228e-02, -1.4365e-01, -4.7737e-01, -5.6638e-01, -4.8802e-01,\n",
      "        -1.1429e-01,  2.8087e-01, -5.7160e-02,  2.3862e-01,  3.5440e-01,\n",
      "         5.8237e-01,  1.2777e-01,  1.0363e-01,  3.0538e-01,  2.0989e-01,\n",
      "         1.1693e-01,  2.6346e-01, -1.5832e-01, -1.1380e-01,  1.7190e-02,\n",
      "        -3.4661e-02,  1.1470e-01,  3.2024e-02, -1.9781e-01, -1.2561e-01,\n",
      "        -4.8289e-02, -2.4562e-01,  5.0646e-03, -2.4147e-02,  2.2932e-01,\n",
      "        -1.9112e-01, -4.4624e-01,  8.6932e-02, -6.9348e-02, -2.6828e-01,\n",
      "         3.0473e-01,  3.3020e-01,  1.4786e-01,  3.7107e-01, -7.5337e-02,\n",
      "         3.3730e-01, -2.6694e-01, -1.1731e-01,  7.5014e-02,  4.6462e-01,\n",
      "        -1.4554e-01,  2.2035e-02,  3.7995e-01,  3.0877e-01,  3.8793e-01,\n",
      "        -5.0270e-02, -8.4905e-02, -1.6390e-01,  5.2378e-01,  1.8881e-01,\n",
      "         2.1466e-02, -8.5598e-02,  2.4094e-01,  3.2501e-01, -2.4542e-01,\n",
      "        -2.2705e-01, -2.5746e-01,  2.9763e-01, -1.7600e-02, -8.6889e-01,\n",
      "         1.7624e-01,  2.9194e-02,  7.0749e-02, -2.1513e-01, -3.4476e-01,\n",
      "        -1.7142e-01,  3.5134e-01,  3.5487e-01, -1.6037e-01,  2.3332e-01,\n",
      "        -1.6640e-01,  1.5522e-02, -1.3603e-01,  9.8263e-01, -1.6572e-01,\n",
      "         8.6756e-02,  1.7276e-02,  3.1124e-02,  4.5487e-01,  9.1418e-02,\n",
      "        -1.2291e-01,  2.6948e-01,  7.5360e-02,  8.1167e-02, -2.8039e-01,\n",
      "         8.6070e-02,  2.8712e-01, -3.2012e-01, -1.0920e-01, -3.4677e-01,\n",
      "        -2.3220e-01,  1.7452e-01, -8.9247e-01, -3.8039e-01,  1.6933e-01,\n",
      "        -4.0088e-02,  7.6205e-02,  2.0971e-01,  4.3188e-01, -5.6367e-02,\n",
      "         4.2553e-01,  6.6854e-02, -4.0933e-01,  2.4338e-01, -9.9158e-02,\n",
      "        -1.1955e-01, -3.4792e-01, -7.9455e-02,  2.1930e-01,  3.0778e-01,\n",
      "         3.1283e-01,  8.8517e-02,  1.4369e-01,  1.2767e-02, -2.3661e-01,\n",
      "        -2.5115e-01, -1.8090e-02,  9.1525e-02,  2.6675e-03,  3.7868e-01,\n",
      "        -1.7585e-01, -1.7576e-01,  4.4584e-01, -3.5462e-01, -3.4920e-01,\n",
      "         4.2924e-02,  1.1444e-02,  5.6267e-01,  5.9517e-03,  4.5876e-02,\n",
      "        -1.8924e+00,  6.9178e-02,  4.4243e-01, -1.2979e-02,  3.2357e-01,\n",
      "        -5.8836e-03,  5.9261e-01, -6.0558e-01,  1.8617e-01, -3.9271e-01,\n",
      "         2.7042e-01, -3.7876e-01, -2.2174e-01,  1.2152e-01,  3.6275e-01,\n",
      "        -1.9326e-01,  6.0438e-02, -3.5042e-01,  1.2261e-01, -4.3831e-02,\n",
      "        -1.9312e-01,  1.5187e-01,  1.3780e-01, -9.7899e-02, -3.7317e-01,\n",
      "         1.2430e+00,  3.2932e-01, -1.9085e-01,  2.1563e-01, -1.0158e-01,\n",
      "        -1.9931e-01,  4.1640e-01,  7.6540e-02, -2.9979e-01, -6.5525e-03,\n",
      "        -7.7947e-02,  4.2820e-03, -5.3287e-02, -2.8932e-01, -3.4238e-01,\n",
      "         2.9741e-01, -7.0199e-02, -4.5928e-01,  2.9630e-01, -2.5724e-01,\n",
      "        -1.6242e-01, -8.9294e-02,  1.3588e-01,  1.9840e-01,  7.3456e-02,\n",
      "         2.5921e-01,  1.7004e-01,  1.0998e-01,  2.1080e-01, -3.7167e-01,\n",
      "         8.9602e-02, -2.4094e-02,  3.9413e-02,  9.6414e-02, -3.9217e-01,\n",
      "        -1.8365e-01,  1.1395e-01,  4.8770e-01,  1.1221e-03, -1.9569e-01,\n",
      "        -1.2228e-02,  3.1669e-01,  2.1529e-01,  2.5503e-01, -2.3742e-01,\n",
      "         3.5058e-02, -8.1064e-01,  2.4613e-03, -2.6651e-01,  4.3942e-01,\n",
      "         1.9389e-02,  6.3594e-02, -2.3803e-01,  9.2669e-02,  1.8258e-01,\n",
      "        -3.8494e-02,  2.3593e-01,  5.7420e-01, -2.0413e-01, -4.4064e-01,\n",
      "         5.3445e-02, -1.5976e-01,  1.8722e-02, -1.0571e-01,  1.6751e-01,\n",
      "        -5.6544e-02,  3.5808e-02, -1.6339e-01, -1.2839e+00, -1.0260e-01,\n",
      "        -6.7205e-02,  1.2519e-01,  9.1995e-02, -4.3033e-02, -7.7112e-02,\n",
      "        -1.9279e-01,  4.8786e-01, -4.6132e-02,  2.3583e-01, -5.8109e-01,\n",
      "        -3.5453e-01, -1.2584e-01, -1.9348e-01, -1.5997e-02,  8.0767e-02,\n",
      "         7.3326e-03,  3.1523e-01, -4.2058e-01, -2.6259e-01, -2.7528e-02,\n",
      "        -1.1586e-01,  5.3807e-03,  4.3207e-01,  2.3536e-01, -5.6140e-01,\n",
      "        -9.4499e-02, -1.6396e-01,  1.5114e-01,  2.6866e-01, -5.2128e-02,\n",
      "         2.1231e-01, -1.9070e-02, -3.1587e-01, -3.1075e+00, -9.8636e-02,\n",
      "        -2.5031e-01, -4.1425e-01,  2.7539e-01, -5.0086e-01, -1.8764e-01,\n",
      "        -1.1095e-01, -3.1184e-01, -1.1116e-01, -3.4540e-01, -2.2962e-01,\n",
      "         2.4196e-01,  2.2008e-01,  2.9891e-01, -1.4837e-01,  2.3513e-01,\n",
      "        -1.4459e-01, -7.1073e-02,  3.1104e-01,  8.4301e-02, -4.1443e-01,\n",
      "         1.9445e-01, -1.7383e-01,  1.0017e-01,  3.1795e-01, -2.7422e-01,\n",
      "         3.4965e-01, -4.7570e-01, -1.1109e-01, -4.1904e-01,  1.8018e-01,\n",
      "        -3.4424e-01, -4.1224e-01,  3.8817e-01,  5.1788e-02, -5.0654e-01,\n",
      "         1.2701e-01,  5.8633e-01, -7.6471e-02,  1.5943e-01,  4.0271e-01,\n",
      "        -1.7491e-01,  8.8953e-02,  4.1438e-01,  7.0470e-02, -2.2776e-01,\n",
      "        -5.2665e-01, -4.8418e-02,  4.7993e-01,  2.6683e-01,  5.4172e-02,\n",
      "         3.4134e-01, -2.9446e-02,  2.8612e-01, -1.2683e-01,  3.2365e-01,\n",
      "         1.5207e-02,  7.5879e-02, -2.1957e-01,  4.3722e-01, -1.9480e-01,\n",
      "        -1.4549e-01,  2.1158e-01, -1.9193e-01,  8.2931e-02, -2.9274e-01,\n",
      "        -3.1520e-02,  8.2016e-02,  1.0614e-02, -2.1728e-01, -2.4810e-01,\n",
      "         8.3925e-02, -9.3397e-01,  9.7814e-02, -8.4303e-02, -1.4857e-01,\n",
      "        -5.1369e-02,  3.3001e-01,  1.8646e-01,  1.0419e-01, -2.0374e-01,\n",
      "        -3.7990e-02, -1.5000e-01,  4.2839e-02, -1.1730e-01, -4.0051e-01,\n",
      "        -2.3397e-01, -7.2866e-01, -3.5928e-01,  4.2980e-01,  2.0247e-01,\n",
      "         4.7775e-02, -1.8988e-01,  1.4026e-01,  4.7262e-01,  2.9465e-01,\n",
      "        -4.6721e-01,  4.3352e-02, -1.1868e-01, -7.1534e-01, -3.5330e-01,\n",
      "         6.3016e-01, -4.8528e-01, -3.8960e-02, -2.2114e-01, -2.4189e-01,\n",
      "        -6.2859e-02, -1.5962e-01, -1.5015e-01,  2.2635e-01, -2.9310e-01,\n",
      "         1.4918e-01, -2.4853e-01,  1.8756e-01, -1.7818e-01,  1.5790e-02,\n",
      "         8.9519e-01, -9.1420e-02,  3.9348e-01,  3.9633e-02,  4.3769e-01,\n",
      "         8.2128e-02, -2.6583e-01,  1.0719e-01,  2.4877e-01,  4.1521e-01,\n",
      "        -3.0047e-01,  1.6897e-01, -1.7872e-01, -1.7884e-01, -3.6049e-02,\n",
      "         6.8345e-02, -3.4804e-01, -9.3207e-02, -3.3487e-02, -1.9079e-01,\n",
      "        -4.7731e-02,  2.1589e-01, -1.7649e-02,  1.0272e-01,  2.2214e-01,\n",
      "         2.4598e-02,  8.8886e-02, -1.9065e-02,  4.7940e-01,  1.7632e-01,\n",
      "         4.2462e-02,  4.0794e-01,  1.7895e-01, -3.6609e-01, -2.2922e-01,\n",
      "         1.1337e-01, -5.0475e-01,  2.0761e-01, -5.2469e-01,  2.5813e-01,\n",
      "         2.0181e-01, -2.5736e-02, -2.3437e-01, -4.9483e-02,  9.1705e-02,\n",
      "        -6.4364e-02,  1.2149e-01, -4.1186e-01,  9.7710e-02, -1.2508e-01,\n",
      "         4.0764e-02, -3.4717e-01,  3.8143e-01,  7.6530e-02, -1.9414e-01,\n",
      "         1.8410e-01, -1.1919e-02, -2.0051e-01,  1.1443e-01,  1.8088e-01,\n",
      "        -1.7253e-01, -1.7402e-01,  1.1461e-01, -2.6830e-01, -9.8872e-02,\n",
      "         3.9775e-02,  1.3449e-01, -1.6283e-01,  2.1166e-03, -7.8609e-02,\n",
      "        -4.6200e-01,  5.7786e-01,  1.1279e-01,  1.9048e-01, -3.5723e-02,\n",
      "         2.1164e-01, -1.4712e-02, -3.3993e-01, -1.2703e-01,  1.0326e-01,\n",
      "         5.0950e-03,  3.7435e-01,  1.7189e-01,  5.8345e-01,  1.6680e-02,\n",
      "        -1.5684e-01,  1.5378e-01,  2.2153e-01, -2.6531e-01,  2.5017e-01,\n",
      "         4.2574e-01, -1.5066e-01,  2.1265e-01,  1.1999e-01, -4.2866e-01,\n",
      "         2.5088e-02,  2.5251e-01,  1.4382e-01,  2.3328e-01,  2.0313e-01,\n",
      "         1.7169e-01,  2.3621e-02,  5.1524e-02, -4.0106e-02, -2.4421e-01,\n",
      "        -3.3787e-01, -2.7906e-01,  8.5632e-02,  3.7364e-01,  3.3528e-01,\n",
      "        -2.2078e-01, -4.9876e-03,  4.2257e-02,  1.6184e-01,  2.2989e-01,\n",
      "         1.0930e-01,  9.5693e-02,  5.9743e-01,  6.8596e-01, -3.4541e-01,\n",
      "        -3.4690e-02, -4.9943e-02, -4.3827e-02, -9.8946e-03, -1.8423e-02,\n",
      "         6.7103e-02, -2.2259e-02, -2.2984e-02, -4.0703e-01,  2.6124e-01,\n",
      "         4.1154e-01, -2.2699e-02, -1.9614e-01, -9.2900e-02, -7.1759e-02,\n",
      "        -1.3627e-01, -2.9177e-01, -9.5439e-03, -2.9971e-01, -2.9885e-02,\n",
      "         4.1862e-01,  5.2152e-02,  6.1977e-02, -1.9548e-01,  1.2748e-01,\n",
      "         1.7454e-02,  2.9819e-01, -1.5988e-01,  1.5838e-02, -8.1304e-02,\n",
      "         1.8233e-02,  7.7923e-02,  1.7629e-01,  1.3150e-01, -1.5991e-01,\n",
      "         2.5084e-01,  2.5934e-01, -2.0483e-01,  3.1098e-02,  3.3086e-01,\n",
      "        -5.5236e-01, -1.7119e-02, -1.7480e-01,  5.3123e-01,  3.7780e-01,\n",
      "         1.3010e-01, -4.2268e-02,  2.4855e-01, -3.1270e-01, -5.0033e-01,\n",
      "         3.0209e-01, -5.2464e-01,  2.9339e-03,  9.4141e-01, -1.9262e-01,\n",
      "         1.2446e-02, -5.6114e-02, -3.5636e-01,  1.8700e-01, -4.5734e-02,\n",
      "         7.4748e-02, -2.0243e-01,  2.5534e-01, -3.2713e-01,  3.1265e-01,\n",
      "        -3.5376e-01, -5.1488e-02,  1.4935e-01, -3.9786e-02,  1.0336e-02,\n",
      "        -5.6745e-01, -8.2600e-02, -2.4669e-01, -1.2936e-01, -2.3212e-01,\n",
      "         7.3379e-02,  4.0745e-01, -1.6200e-01, -7.2631e-02,  1.1524e-01,\n",
      "        -1.4988e-01, -7.2060e-02,  5.8054e-01, -1.8931e-02,  1.1245e-01,\n",
      "         3.2097e-01, -2.5848e-01,  3.1161e-01,  3.9392e-01, -3.5412e-01,\n",
      "        -1.9400e-01, -1.5293e-01, -2.4102e-01, -3.0125e-02,  3.7008e-01,\n",
      "         2.2403e-01,  7.8257e-02, -2.6900e-01, -3.4572e-01, -2.6427e-03,\n",
      "         1.7712e-02, -1.1895e-01,  4.3233e-02, -8.8320e-02,  4.5462e-03,\n",
      "        -2.5439e-01,  1.4728e-01,  4.8581e-01,  4.9114e-02, -1.8314e-01,\n",
      "        -5.9602e-02,  1.2808e-01, -5.5221e-02, -2.2270e-01, -3.5185e-01,\n",
      "         9.6983e-02,  1.9694e-01, -4.9657e-02, -2.3089e-01,  9.6932e-02,\n",
      "        -5.9364e-02, -1.0977e-01, -1.0774e+00, -1.7037e-01, -5.0537e-01,\n",
      "        -1.3686e-01, -4.6037e-01,  1.6326e-01,  5.6601e-01,  6.3966e-02,\n",
      "        -2.1306e-01, -1.4903e-01,  2.7365e-01,  7.4819e-02, -5.1872e-03,\n",
      "        -5.4667e-02,  4.2225e-01, -1.0746e-01,  3.5039e-02, -3.6283e-01,\n",
      "         4.7700e-02, -3.4952e-02,  2.4087e-01, -1.5248e-02, -1.0470e-01,\n",
      "        -2.1243e-01, -5.1084e-01,  3.7812e-02, -2.0370e-01,  8.7616e-03,\n",
      "        -5.5488e-03, -1.4413e-02, -1.5388e-01,  2.1188e-01,  6.3782e-02,\n",
      "         2.0168e-01, -4.1447e-01,  1.8987e-01,  1.7409e-01,  1.5857e-01,\n",
      "         1.0428e-02, -2.3079e-01, -2.0696e-01,  1.5372e-01, -1.3400e-01,\n",
      "        -6.5152e-02, -9.0121e-02,  1.3587e-01, -1.1827e-01, -2.9220e-02,\n",
      "         9.5783e-02,  6.6440e-02, -2.1316e-02, -2.3742e-01, -1.7472e-01,\n",
      "        -7.9916e-01,  4.4483e-02,  2.8404e-01, -2.2308e-02, -5.6765e-02,\n",
      "         1.9825e-01, -2.0278e-01,  3.3376e-01, -5.7932e-02, -2.7878e-01,\n",
      "         4.6812e-01,  2.6236e-01, -9.5878e-02, -1.5614e-01, -1.8900e-01,\n",
      "        -4.5505e-02, -1.4836e-01, -7.0388e-02, -2.5256e-01, -3.6207e-02,\n",
      "        -2.3713e-01,  1.1566e-01, -6.3016e-02, -1.5543e-01, -1.6353e-01,\n",
      "         1.1100e-01, -5.8401e-02, -4.0934e-01, -5.6329e-02, -1.1422e-01,\n",
      "         4.5686e-01,  1.9147e-01, -2.4061e+00, -1.3890e-01,  4.9572e-02,\n",
      "         1.0699e-01,  1.8370e-01, -4.5470e-02, -8.1192e-02, -1.1795e-01,\n",
      "        -1.3250e-01, -3.6430e-02,  2.8795e-01, -7.0326e-02,  9.9013e-02,\n",
      "         7.5754e-02, -8.5289e-02, -2.4366e-02])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()\n",
    "print(sentence_embedding)\n",
    "print(sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
